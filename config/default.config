[train] #train parameters
epoch = 16
batch_size = 128

shuffle = True

reader_num = 8

optimizer = adam
learning_rate = 1e-3
weight_decay = 0
step_size = 1
lr_multiplier = 1



[eval] #eval parameters
batch_size = 128

shuffle = False

reader_num = 4

[distributed]
use = false
backend = nccl

[data] #data parameters


load_into_mem = True

[model] #model parameters


[output] #output parameters
output_time = 1
test_time = 1

